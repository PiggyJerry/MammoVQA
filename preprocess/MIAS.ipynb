{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIAS-breast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def np_CountUpContinuingOnes(b_arr):\n",
    "    left = np.arange(len(b_arr))\n",
    "    left[b_arr > 0] = 0\n",
    "    left = np.maximum.accumulate(left)\n",
    "    rev_arr = b_arr[::-1]\n",
    "    right = np.arange(len(rev_arr))\n",
    "    right[rev_arr > 0] = 0\n",
    "    right = np.maximum.accumulate(right)\n",
    "    right = len(rev_arr) - 1 - right[::-1]\n",
    "    return right - left - 1\n",
    "\n",
    "def ExtractBreast(img):\n",
    "    img_copy = img.copy()\n",
    "    img = np.where(img <= 20, 0, img)\n",
    "    height, _ = img.shape\n",
    "    y_a = height // 2 + int(height * 0.4)\n",
    "    y_b = height // 2 - int(height * 0.4)\n",
    "    b_arr = img[y_b:y_a].std(axis=0) != 0\n",
    "    continuing_ones = np_CountUpContinuingOnes(b_arr)\n",
    "    col_ind = np.where(continuing_ones == continuing_ones.max())[0]\n",
    "    img = img[:, col_ind]\n",
    "    _, width = img.shape\n",
    "    x_a = width // 2 + int(width * 0.4)\n",
    "    x_b = width // 2 - int(width * 0.4)\n",
    "    b_arr = img[:, x_b:x_a].std(axis=1) != 0\n",
    "    continuing_ones = np_CountUpContinuingOnes(b_arr)\n",
    "    row_ind = np.where(continuing_ones == continuing_ones.max())[0]\n",
    "    return img_copy[row_ind][:, col_ind]\n",
    "\n",
    "# 定义路径\n",
    "TXT_PATH = '/Volumes/图图/MIAS/archive/Info.txt'\n",
    "PGM_PATH = '/Volumes/图图/MIAS/archive/all-mias'\n",
    "OUTPUT_BASE_PATH = 'Benchmark/MIAS-breast'\n",
    "\n",
    "# 读取TXT文件\n",
    "with open(TXT_PATH, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# 跳过标题行\n",
    "lines = lines[1:]\n",
    "\n",
    "# 初始化一个字典，用于合并相同的 refnum 信息\n",
    "merged_data = {}\n",
    "\n",
    "for line in lines:\n",
    "    parts = line.split()\n",
    "    refnum = parts[0]\n",
    "    bg = str(parts[1]).replace(' ', '')\n",
    "    cls = str(parts[2]).replace(' ', '')\n",
    "    severity = str(parts[3]).replace(' ', '') if len(parts) > 3 else 'N'\n",
    "    if refnum in merged_data:\n",
    "        merged_data[refnum]['class'].add(cls)\n",
    "        if severity == 'M':\n",
    "            merged_data[refnum]['severity'] = 'M'\n",
    "    else:\n",
    "        merged_data[refnum] = {\n",
    "            'background': bg,\n",
    "            'class': {cls},\n",
    "            'severity': severity\n",
    "        }\n",
    "\n",
    "def process_and_save_all(data):\n",
    "    for refnum, info in data.items():\n",
    "        severity = info['severity']\n",
    "        cancer = 'Yes' if severity == 'M' else 'No'\n",
    "\n",
    "        # 读取 PGM 文件\n",
    "        pgm_file = os.path.join(PGM_PATH, refnum + '.pgm')\n",
    "        if os.path.exists(pgm_file):\n",
    "            img = cv2.imread(pgm_file, cv2.IMREAD_GRAYSCALE)\n",
    "            img = ExtractBreast(img)\n",
    "            img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "            # 创建输出目录\n",
    "            output_dir = os.path.join(OUTPUT_BASE_PATH, refnum)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            # 保存图像为 JPEG 格式\n",
    "            jpg_output_path = os.path.join(output_dir, 'img.jpg')\n",
    "            cv2.imwrite(jpg_output_path, img)\n",
    "\n",
    "            print(f\"Processed {refnum}\")\n",
    "        else:\n",
    "            print(f\"PGM file for {refnum} not found.\")\n",
    "\n",
    "# 处理并保存所有数据\n",
    "process_and_save_all(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIAS-finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def crop_and_save(img, x, y, radius, output_path):\n",
    "    h, w = img.shape\n",
    "    x = int(x)\n",
    "    y = w - int(y)  # Convert y-coordinate from DICOM to image coordinates\n",
    "    radius = int(radius)\n",
    "    x1 = max(x - radius, 0)\n",
    "    y1 = max(y - radius, 0)\n",
    "    x2 = min(x + radius, img.shape[1])\n",
    "    y2 = min(y + radius, img.shape[0])\n",
    "\n",
    "    cropped_img = img[y1:y2, x1:x2]\n",
    "    cropped_img = cv2.normalize(cropped_img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    cv2.imwrite(output_path, cropped_img)\n",
    "\n",
    "# Define paths\n",
    "TXT_PATH = '/Volumes/图图/MIAS/archive/Info.txt'\n",
    "PGM_PATH = '/Volumes/图图/MIAS/archive/all-mias'\n",
    "OUTPUT_BASE_PATH = 'Benchmark/MIAS-finding'\n",
    "\n",
    "# Read TXT file\n",
    "with open(TXT_PATH, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Skip header line and filter lines\n",
    "lines = lines[1:]\n",
    "lines = [line for line in lines if len(line.split()) > 4]\n",
    "\n",
    "def process_and_save_all(lines):\n",
    "    refnum_counter = {}\n",
    "    for line in lines:\n",
    "        parts = line.split()\n",
    "        refnum = parts[0]\n",
    "        cls = str(parts[2]).replace(' ', '')\n",
    "        severity = str(parts[3]).replace(' ', '')\n",
    "        x, y, radius = parts[4], parts[5], parts[6]\n",
    "\n",
    "        # Handle duplicate refnums\n",
    "        if refnum in refnum_counter:\n",
    "            refnum_counter[refnum] += 1\n",
    "        else:\n",
    "            refnum_counter[refnum] = 1\n",
    "        refnum_with_suffix = f\"{refnum}_{refnum_counter[refnum]}\"\n",
    "\n",
    "        # Read PGM file\n",
    "        pgm_file = os.path.join(PGM_PATH, refnum + '.pgm')\n",
    "        if os.path.exists(pgm_file):\n",
    "            img = cv2.imread(pgm_file, cv2.IMREAD_GRAYSCALE)\n",
    "            output_dir = os.path.join(OUTPUT_BASE_PATH, refnum_with_suffix)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            # Save cropped image\n",
    "            jpg_output_path = os.path.join(output_dir, 'img.jpg')\n",
    "            crop_and_save(img, x, y, radius, jpg_output_path)\n",
    "\n",
    "\n",
    "            print(f\"Processed {refnum_with_suffix}\")\n",
    "        else:\n",
    "            print(f\"PGM file for {refnum} not found.\")\n",
    "\n",
    "# Process and save all data\n",
    "process_and_save_all(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate normal case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def find_cropped_image_position(full_image, cropped_image):\n",
    "    res = cv2.matchTemplate(full_image, cropped_image, cv2.TM_CCOEFF_NORMED)\n",
    "    _, _, _, max_loc = cv2.minMaxLoc(res)\n",
    "    top_left = max_loc\n",
    "    bottom_right = (top_left[0] + cropped_image.shape[1], top_left[1] + cropped_image.shape[0])\n",
    "    return (*top_left, *bottom_right)\n",
    "\n",
    "def random_crop_outside_bboxes(full_image, bboxes, crop_size, num_crops=1):\n",
    "    height, width = full_image.shape[:2]\n",
    "    cropped_images = []\n",
    "    \n",
    "    def is_inside_any_bbox(x, y):\n",
    "        for (x1, y1, x2, y2) in bboxes:\n",
    "            if x1 <= x < x2 and y1 <= y < y2:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    for _ in range(num_crops):\n",
    "        while True:\n",
    "            x = random.randint(0, width - crop_size[1])\n",
    "            y = random.randint(0, height - crop_size[0])\n",
    "            if not is_inside_any_bbox(x, y):\n",
    "                cropped_img = full_image[y:y + crop_size[0], x:x + crop_size[1]]\n",
    "                cropped_images.append(cropped_img)\n",
    "                break\n",
    "    return cropped_images\n",
    "\n",
    "def process_all_crops_for_folder(full_image_path, cropped_folders, output_dir):\n",
    "    full_image = cv2.imread(full_image_path+'/img.jpg')\n",
    "    bboxes = []\n",
    "\n",
    "    # Collect bboxes from all crops\n",
    "    try:\n",
    "        for folder in cropped_folders:\n",
    "            for cropped_image_name in os.listdir(folder):\n",
    "                if cropped_image_name.endswith('img.jpg'):\n",
    "                    cropped_image_path = os.path.join(folder, cropped_image_name)\n",
    "                    cropped_image = cv2.imread(cropped_image_path)\n",
    "                    bbox = find_cropped_image_position(full_image, cropped_image)\n",
    "                    bboxes.append(bbox)\n",
    "\n",
    "        # Generate random crops and update info_dict.npy\n",
    "        for idx,folder in enumerate(cropped_folders):\n",
    "\n",
    "            crop_size = (bboxes[idx][3] - bboxes[idx][1], bboxes[idx][2] - bboxes[idx][0])\n",
    "            random_crops = random_crop_outside_bboxes(full_image, bboxes, crop_size)\n",
    "            for crop in random_crops:\n",
    "                normal_folder = os.path.join(output_dir, f\"{os.path.basename(folder)}_normal\")\n",
    "                os.makedirs(normal_folder, exist_ok=True)\n",
    "                normal_image_path = os.path.join(normal_folder, 'img.jpg')\n",
    "                cv2.imwrite(normal_image_path, crop)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(full_image_path+' OOps!')\n",
    "        \n",
    "\n",
    "root_dir = 'Benchmark/MIAS-finding'\n",
    "base_image_dir = 'Benchmark/MIAS-breast'\n",
    "output_dir = 'Benchmark/MIAS-finding'\n",
    "\n",
    "def find_full_image_path(base_dir, full_image_key):\n",
    "    full_image_path = os.path.join(base_dir, full_image_key)\n",
    "    if os.path.exists(full_image_path):\n",
    "        return full_image_path\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Map cropped images to their respective full images\n",
    "full_image_to_crops_map = {}\n",
    "for subdir in os.listdir(root_dir):\n",
    "    full_image_key = '_'.join(subdir.split('_')[:-1])\n",
    "    full_image_to_crops_map.setdefault(full_image_key, []).append(os.path.join(root_dir, subdir))\n",
    "\n",
    "# Process all mapped cropped folders for each full image\n",
    "for full_image_key, folders in full_image_to_crops_map.items():\n",
    "    # patient_id, side, view = full_image_key.split('_')\n",
    "    full_image_path = find_full_image_path(base_image_dir, full_image_key)\n",
    "    if full_image_path:\n",
    "        process_all_crops_for_folder(full_image_path, folders, output_dir)\n",
    "    else:\n",
    "        print(f\"Full image not found for {full_image_key}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
