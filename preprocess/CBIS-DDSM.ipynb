{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBIS-DDSM-breast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import pydicom as pdcm\n",
    "\n",
    "def np_CountUpContinuingOnes(b_arr):\n",
    "    # Calculate indices for continuing zeros from left side\n",
    "    left = np.arange(len(b_arr))\n",
    "    left[b_arr > 0] = 0\n",
    "    left = np.maximum.accumulate(left)\n",
    "\n",
    "    # Calculate indices from right side\n",
    "    rev_arr = b_arr[::-1]\n",
    "    right = np.arange(len(rev_arr))\n",
    "    right[rev_arr > 0] = 0\n",
    "    right = np.maximum.accumulate(right)\n",
    "    right = len(rev_arr) - 1 - right[::-1]\n",
    "\n",
    "    return right - left - 1\n",
    "\n",
    "def ExtractBreast(img):\n",
    "    img_copy = img.copy()\n",
    "    img = np.where(img <= 40, 0, img)\n",
    "    height, _ = img.shape\n",
    "\n",
    "    y_a = height // 2 + int(height * 0.4)\n",
    "    y_b = height // 2 - int(height * 0.4)\n",
    "    b_arr = img[y_b:y_a].std(axis=0) != 0\n",
    "    continuing_ones = np_CountUpContinuingOnes(b_arr)\n",
    "    col_ind = np.where(continuing_ones == continuing_ones.max())[0]\n",
    "    img = img[:, col_ind]\n",
    "\n",
    "    _, width = img.shape\n",
    "    x_a = width // 2 + int(width * 0.4)\n",
    "    x_b = width // 2 - int(width * 0.4)\n",
    "    b_arr = img[:, x_b:x_a].std(axis=1) != 0\n",
    "    continuing_ones = np_CountUpContinuingOnes(b_arr)\n",
    "    row_ind = np.where(continuing_ones == continuing_ones.max())[0]\n",
    "\n",
    "    return img_copy[row_ind][:, col_ind]\n",
    "\n",
    "\n",
    "dataset_dir = \"/Volumes/图图/CBIS-DDSM_kaggle\"\n",
    "df_dicom_info = pd.read_csv(f'{dataset_dir}/csv/dicom_info.csv')\n",
    "df_dicom_info['image_path'] = df_dicom_info['image_path'].apply(lambda x: x.replace('CBIS-DDSM', dataset_dir))\n",
    "\n",
    "\n",
    "description_files = [\n",
    "    f\"{dataset_dir}/csv/mass_case_description_train_set.csv\",\n",
    "    f\"{dataset_dir}/csv/mass_case_description_test_set.csv\",\n",
    "    f\"{dataset_dir}/csv/calc_case_description_train_set.csv\",\n",
    "    f\"{dataset_dir}/csv/calc_case_description_test_set.csv\"\n",
    "]\n",
    "\n",
    "additional_dfs = []\n",
    "for file in description_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df.rename(columns={'breast density': 'breast_density', 'breast_density': 'breast_density'}, inplace=True)\n",
    "    additional_dfs.append(df)\n",
    "additional_df = pd.concat(additional_dfs, ignore_index=True)\n",
    "image_data = []\n",
    "\n",
    "for index, row in tqdm(additional_df.iterrows(), total=len(additional_df)):\n",
    "    patient_id = row['image file path'].split('/')[0]\n",
    "    img_row = df_dicom_info[df_dicom_info['image_path'].apply(lambda x: x.split('/')[-2]) == row['image file path'].split('/')[-2]]\n",
    "    \n",
    "    if img_row.empty:\n",
    "        print(f\"No image info for patient_id: {patient_id}\")\n",
    "        continue\n",
    "\n",
    "    img_path = img_row['image_path'].values[0]\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Failed to read image: {img_path}\")\n",
    "        continue\n",
    "    \n",
    "    img = ExtractBreast(img)\n",
    "\n",
    "    info_dict = {\n",
    "        \"patient_id\": patient_id,\n",
    "        \"img_path\": img_path,\n",
    "    }\n",
    "    \n",
    "    image_data.append(info_dict)\n",
    "\n",
    "\n",
    "image_df = pd.DataFrame(image_data)\n",
    "\n",
    "def save_images_and_info(df, output_base_dir):\n",
    "    for _, row in df.iterrows():\n",
    "        patient_id = row['patient_id']\n",
    "        output_dir = os.path.join(output_base_dir, patient_id)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "\n",
    "        img = cv2.imread(row['img_path'], cv2.IMREAD_GRAYSCALE)\n",
    "        img = ExtractBreast(img)\n",
    "        img_output_path = os.path.join(output_dir, 'img.jpg')\n",
    "        cv2.imwrite(img_output_path, cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8))\n",
    "        \n",
    "        print(f\"Saved {patient_id} images to {output_dir}\")\n",
    "\n",
    "\n",
    "output_base_dir = \"Benchmark/CBIS-DDSM-breast\"\n",
    "save_images_and_info(image_df, output_base_dir)\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBIS-DDSM-finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import pydicom as pdcm\n",
    "\n",
    "\n",
    "dataset_dir = \"/Volumes/图图/CBIS-DDSM_kaggle\"\n",
    "df = pd.read_csv(f'{dataset_dir}/csv/dicom_info.csv')\n",
    "df['image_path'] = df['image_path'].apply(lambda x: x.replace('CBIS-DDSM', dataset_dir))\n",
    "\n",
    "\n",
    "description_files = [\n",
    "    f\"{dataset_dir}/csv/mass_case_description_train_set.csv\",\n",
    "    f\"{dataset_dir}/csv/mass_case_description_test_set.csv\",\n",
    "    f\"{dataset_dir}/csv/calc_case_description_train_set.csv\",\n",
    "    f\"{dataset_dir}/csv/calc_case_description_test_set.csv\"\n",
    "]\n",
    "additional_dfs = [pd.read_csv(file) for file in description_files]\n",
    "additional_df = pd.concat(additional_dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "all_data = []\n",
    "for index, row in tqdm(additional_df.iterrows(), total=len(additional_df)):\n",
    "    patient_id = row['cropped image file path'].split('/')[0]\n",
    "    img_row = df[df['image_path'].apply(lambda x: x.split('/')[-2]) == row['cropped image file path'].split('/')[-2]]\n",
    "    \n",
    "    if img_row.empty:\n",
    "        print(f\"No image info for patient_id: {patient_id}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        img_path = img_row[img_row['SeriesDescription'] == 'cropped images']['image_path'].values[0]\n",
    "    except:\n",
    "        print(f\"Multiple or no entries found for patient_id: {patient_id}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    all_data.append({\n",
    "        \"patient_id\": patient_id,\n",
    "        \"img_path\": img_path,\n",
    "    })\n",
    "\n",
    "\n",
    "all_data_df = pd.DataFrame(all_data)\n",
    "\n",
    "def save_images_and_info(df, output_base_dir):\n",
    "    for _, row in df.iterrows():\n",
    "        patient_id = row['patient_id']\n",
    "        output_dir = os.path.join(output_base_dir, patient_id)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "        img = cv2.imread(row['img_path'], cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Failed to read image: {row['img_path']}\")\n",
    "            continue\n",
    "        \n",
    "        img_output_path = os.path.join(output_dir, 'img.jpg')\n",
    "        cv2.imwrite(img_output_path, cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8))\n",
    "       \n",
    "        print(f'Saved {patient_id} image to {output_dir}')\n",
    "\n",
    "\n",
    "output_base_dir = \"Benchmark/CBIS-DDSM-finding\"\n",
    "save_images_and_info(all_data_df, os.path.join(output_base_dir, 'All_Data'))\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def find_cropped_image_position(full_image, cropped_image):\n",
    "    res = cv2.matchTemplate(full_image, cropped_image, cv2.TM_CCOEFF_NORMED)\n",
    "    _, _, _, max_loc = cv2.minMaxLoc(res)\n",
    "    top_left = max_loc\n",
    "    bottom_right = (top_left[0] + cropped_image.shape[1], top_left[1] + cropped_image.shape[0])\n",
    "    return (*top_left, *bottom_right)\n",
    "\n",
    "def random_crop_outside_bboxes(full_image, bboxes, crop_size, num_crops=1):\n",
    "    height, width = full_image.shape[:2]\n",
    "    cropped_images = []\n",
    "    \n",
    "    def is_inside_any_bbox(x, y):\n",
    "        for (x1, y1, x2, y2) in bboxes:\n",
    "            if x1 <= x < x2 and y1 <= y < y2:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    for _ in range(num_crops):\n",
    "        while True:\n",
    "            x = random.randint(0, width - crop_size[1])\n",
    "            y = random.randint(0, height - crop_size[0])\n",
    "            if not is_inside_any_bbox(x, y):\n",
    "                cropped_img = full_image[y:y + crop_size[0], x:x + crop_size[1]]\n",
    "                cropped_images.append(cropped_img)\n",
    "                break\n",
    "    return cropped_images\n",
    "\n",
    "def process_all_crops_for_folder(full_image_path, cropped_folders, output_dir):\n",
    "    full_image = cv2.imread(full_image_path+'/img.jpg')\n",
    "    bboxes = []\n",
    "\n",
    "    # Collect bboxes from all crops\n",
    "    try:\n",
    "        for folder in cropped_folders:\n",
    "            for cropped_image_name in os.listdir(folder):\n",
    "                if cropped_image_name.endswith('img.jpg'):\n",
    "                    cropped_image_path = os.path.join(folder, cropped_image_name)\n",
    "                    cropped_image = cv2.imread(cropped_image_path)\n",
    "                    bbox = find_cropped_image_position(full_image, cropped_image)\n",
    "                    bboxes.append(bbox)\n",
    "\n",
    "        # Generate random crops and update info_dict.npy\n",
    "        for idx,folder in enumerate(cropped_folders):\n",
    "            cropped_image_name=os.path.join(folder, 'img.jpg')\n",
    "            crop_size = (bboxes[idx][3] - bboxes[idx][1], bboxes[idx][2] - bboxes[idx][0])\n",
    "            random_crops = random_crop_outside_bboxes(full_image, bboxes, crop_size)\n",
    "            for crop in random_crops:\n",
    "                normal_folder = os.path.join(output_dir, f\"{os.path.basename(folder)}_normal\")\n",
    "                os.makedirs(normal_folder, exist_ok=True)\n",
    "                normal_image_path = os.path.join(normal_folder, 'img.jpg')\n",
    "                cv2.imwrite(normal_image_path, crop)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(full_image_path+' OOps!')\n",
    "        \n",
    "\n",
    "root_dir = 'Benchmark/CBIS-DDSM-finding'\n",
    "base_image_dir = 'Benchmark/CBIS-DDSM-breast'\n",
    "output_dir = 'Benchmark/CBIS-DDSM-finding'\n",
    "\n",
    "def find_full_image_path(base_dir, full_image_key):\n",
    "    full_image_path = os.path.join(base_dir, full_image_key)\n",
    "    if os.path.exists(full_image_path):\n",
    "        return full_image_path\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Map cropped images to their respective full images\n",
    "full_image_to_crops_map = {}\n",
    "for subdir in os.listdir(root_dir):\n",
    "    full_image_key = '_'.join(subdir.split('_')[:5])\n",
    "    full_image_to_crops_map.setdefault(full_image_key, []).append(os.path.join(root_dir, subdir))\n",
    "\n",
    "# Process all mapped cropped folders for each full image\n",
    "for full_image_key, folders in full_image_to_crops_map.items():\n",
    "    full_image_path = find_full_image_path(base_image_dir, full_image_key)\n",
    "    if full_image_path:\n",
    "        process_all_crops_for_folder(full_image_path, folders, output_dir)\n",
    "    else:\n",
    "        print(f\"Full image not found for {full_image_key}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
